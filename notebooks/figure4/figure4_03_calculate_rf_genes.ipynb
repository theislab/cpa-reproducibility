{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import anndata\n",
    "from utils import *\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True /storage/groups/ml01/workspace/mo/for_nacho/Norman2019_prep_new.h5ad\n",
      "True /storage/groups/ml01/workspace/carlo.dedonno/cpa-reproducibility/fig4_predicted_adata_full.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True /storage/groups/ml01/workspace/carlo.dedonno/cpa-reproducibility/figure4_latent_adata.h5ad\n",
      "\n",
      "dimensions of embedding: (497800, 64)\n",
      "all good. Removing datasets based on repetition is then tractable\n"
     ]
    }
   ],
   "source": [
    "means = utils.get_means()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# uniq combinations\n",
      "{'CKS1B', 'ELMSAN1', 'TGFBR2', 'SLC6A9', 'DLX2', 'RUNX1T1', 'GLB1L2', 'HES7', 'KMT2A', 'KIAA1804', 'MAPK1', 'CBL', 'CNNM4', 'MAP7D1', 'IKZF3', 'ETS2', 'FOXL2', 'CEBPA', 'OSR2', 'ctrl', 'DUSP9', 'PTPN13', 'TBX3', 'HNF4A', 'FOSB', 'POU3F2', 'CEBPE', 'CELF2', 'COL2A1', 'ZC3HAV1', 'MAP4K5', 'NCL', 'RHOXF2', 'IGDCC3', 'NIT1', 'ARID1A', 'STIL', 'KIF18B', 'JUN', 'AHR', 'CLDN6', 'C19orf26', 'CDKN1C', 'CNN1', 'HK2', 'CDKN1B', 'ZBTB25', 'BCORL1', 'IRF1', 'MEIS1', 'PTPN1', 'SLC38A2', 'BPGM', 'UBASH3A', 'ZBTB1', 'ZNF318', 'ARRDC3', 'ISL2', 'CDKN1A', 'PRDM1', 'SLC4A1', 'ATL1', 'HOXA13', 'BCL2L11', 'PTPN12', 'MIDN', 'PTPN9', 'UBASH3B', 'TSC22D1', 'SPI1', 'TBX2', 'SNAI1', 'KIF2C', 'HOXB9', 'SET', 'COL1A1', 'IER5L', 'RREB1', 'BAK1', 'PLK4', 'CBFA2T3', 'MAP2K6', 'EGR1', 'MAP2K3', 'ZBTB10', 'SAMD1', 'MAP4K3', 'FOXO4', 'MAML2', 'TMSB4X', 'CSRNP1', 'CEBPB', 'FOXF1', 'LYL1', 'FEV', 'LHX1', 'FOXA1', 'HOXC13', 'CITED1', 'TP73', 'S1PR2', 'KLF1', 'PRTG', 'FOXA3', 'SGK1', 'C3orf72'}\n",
      "5565\n"
     ]
    }
   ],
   "source": [
    "print('# uniq combinations')\n",
    "uniq = set([x for lab in ['a', 'b'] for x in means.obs[lab] if str(x) != 'nan'])\n",
    "print(uniq)\n",
    "import itertools\n",
    "print(len(list(itertools.combinations(uniq, r=2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [c for c in combinations([s for s in set(means.obs[['a', 'b']].values.flatten()) if str(s) != 'nan'], r=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5565"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means.obs.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def calculate_rf_multithread(a, b):\n",
    "#     # gene_names = set(ori.obs[['a', 'b']].values.flatten())\n",
    "#     print(a, b)\n",
    "\n",
    "#     if str(a) == 'nan' or a == 'ctrl':\n",
    "#         return\n",
    "#     if str(b) == 'nan' or b == 'ctrl':\n",
    "#         return\n",
    "#     bkp_path = '../data/rf_genes/%s_%s.pkl' % (a, b)\n",
    "#     print(os.path.exists(bkp_path), bkp_path)\n",
    "#     if os.path.exists(bkp_path):\n",
    "#         return\n",
    "#     try:\n",
    "#         print(a, b)\n",
    "#         ctrl = means[means.obs['condition'] == 'ctrl']\n",
    "#         gene_name = a\n",
    "#         lab_cond_a = {'%s+ctrl' % a, 'ctrl+%s' % a}\n",
    "#         lab_cond_b = {'%s+ctrl' % b, 'ctrl+%s' % b}\n",
    "#         cond_single_a = means[means.obs['condition'].isin(lab_cond_a),:]\n",
    "#         cond_single_b = means[means.obs['condition'].isin(lab_cond_b),:]\n",
    "\n",
    "#         lab_cond_double = {'%s+%s' % (a, b), '%s+%s' % (b, a)}\n",
    "#         cond_double_ab_ori = means[means.obs['condition'].isin(lab_cond_double),:]\n",
    "#         cond_double_ab_pred = means[means.obs['condition'].isin(lab_cond_double),:]\n",
    "\n",
    "#         print(cond_double_ab_ori.shape, cond_double_ab_pred.shape)\n",
    "#         ctrl.obs['location'] = 'control'\n",
    "#         cond_single_a.obs['location'] = 'a'\n",
    "#         cond_single_b.obs['location'] = 'b'\n",
    "#         cond_double_ab_ori.obs['location'] = 'ab'\n",
    "#         cond_double_ab_pred.obs['location'] = 'ab'\n",
    "\n",
    "#         cond_double_sel = cond_double_ab_ori if cond_double_ab_ori.shape[0] != 0 else cond_double_ab_pred if cond_double_ab_pred.shape[0] != 0 else None\n",
    "\n",
    "#         if cond_double_sel is None:\n",
    "#             return\n",
    "#         assert cond_double_sel is not None\n",
    "\n",
    "#         print(ctrl.shape, cond_single_a.shape, cond_single_b.shape, cond_double_sel.shape)\n",
    "\n",
    "#         # this will throw an error sometimes because the var_names of ori and pred are not the same\n",
    "#         ad2 = ctrl.concatenate([cond_single_a, cond_single_b, cond_double_sel])\n",
    "#         # ad = ad.concatenate(cond_double)\n",
    "\n",
    "#         print(list(ad2.obs['location'].value_counts()))\n",
    "\n",
    "#         # print(ad2.shape)\n",
    "\n",
    "#         X, y = np.array(ad2.to_df()), np.array(ad2.obs['location'])\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=500, stratify=y)\n",
    "\n",
    "#         clf_tree = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "#         # print('fitting RF....')\n",
    "#         clf_tree.fit(X_train, y_train)\n",
    "\n",
    "#         y_predict = clf_tree.predict(X_test)\n",
    "#         acc = accuracy_score(y_test, y_predict)\n",
    "#         # print('Feature prediction accuracy (test size: {1:.1f}%): {0}\\n'.format(acc, 100*.2))\n",
    "\n",
    "#         X, y = np.array(ad2.to_df()), np.array(ad2.obs['location'])\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=500, stratify=y)\n",
    "\n",
    "#         clf_tree = RandomForestClassifier(class_weight='balanced')\n",
    "#         clf_tree.fit(X_train, y_train)\n",
    "\n",
    "#         y_predict = clf_tree.predict(X_test)\n",
    "#         acc = accuracy_score(y_test, y_predict)\n",
    "#         print('Feature prediction accuracy (test size: {1:.1f}%): {0}\\n'.format(acc, 100*.2))\n",
    "\n",
    "#         importances = clf_tree.feature_importances_\n",
    "#         importances = pd.Series(importances, index=ad2.var.index).sort_values(ascending=False)\n",
    "\n",
    "#         print('saving object')\n",
    "#         pickle.dump(importances, open(bkp_path, 'wb'))        \n",
    "#     except IOError:\n",
    "#         print('error with gene', a, b)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_genes = set(means.obs[['a', 'b']].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 CKS1B S1PR2\n",
      "200 ELMSAN1 FOXA1\n",
      "300 TGFBR2 LYL1\n",
      "400 SLC6A9 CEBPB\n",
      "500 DLX2 CSRNP1\n",
      "600 RUNX1T1 CSRNP1\n",
      "700 GLB1L2 CEBPB\n",
      "800 HES7 LYL1\n",
      "900 KMT2A FOXA1\n",
      "1000 MAPK1 S1PR2\n",
      "1100 KIAA1804 C3orf72\n",
      "1200 CNNM4 OSR2\n",
      "1300 MAP7D1 CEBPE\n",
      "1400 IKZF3 ARID1A\n",
      "1500 ETS2 CDKN1B\n",
      "1600 FOXL2 ARRDC3\n",
      "1700 CEBPA TSC22D1\n",
      "1800 OSR2 MAP2K6\n",
      "1900 ctrl LHX1\n",
      "2000 PTPN13 CEBPE\n",
      "2100 TBX3 CDKN1C\n",
      "2200 HNF4A ATL1\n",
      "2300 FOSB CBFA2T3\n",
      "2400 POU3F2 S1PR2\n",
      "2500 CELF2 CDKN1C\n",
      "2600 COL2A1 PTPN9\n",
      "2700 ZC3HAV1 CSRNP1\n",
      "2800 NCL C19orf26\n",
      "2900 RHOXF2 TSC22D1\n",
      "3000 IGDCC3 FOXA1\n",
      "3100 ARID1A ZNF318\n",
      "3200 STIL MAP4K3\n",
      "3300 JUN PTPN1\n",
      "3400 AHR SAMD1\n",
      "3500 C19orf26 ARRDC3\n",
      "3600 CNN1 LYL1\n",
      "3700 HK2 TBX2\n",
      "3800 ZBTB25 PTPN1\n",
      "3900 BCORL1 LYL1\n",
      "4000 MEIS1 CBFA2T3\n",
      "4100 PTPN1 SNAI1\n",
      "4200 UBASH3A PTPN9\n",
      "4300 ZNF318 MIDN\n",
      "4400 ISL2 TSC22D1\n",
      "4500 PRDM1 COL1A1\n",
      "4600 ATL1 MAP4K3\n",
      "4700 BCL2L11 KLF1\n",
      "4800 PTPN9 MAP2K6\n",
      "4900 SPI1 TBX2\n",
      "5000 SNAI1 KLF1\n",
      "5100 SET C3orf72\n",
      "5200 BAK1 CEBPB\n",
      "5300 EGR1 LYL1\n",
      "5400 FOXO4 LYL1\n",
      "5500 FEV LHX1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for g1, g2 in itertools.combinations(uniq_genes, r=2):\n",
    "    if str(g1) == 'nan':\n",
    "        continue\n",
    "    if str(g2) == 'nan':\n",
    "        continue\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    # if not 'KLF1' in g1 and not 'KLF1' in g2:\n",
    "    #     continue\n",
    "    # if not 'FOXA3' in g1 and not 'FOXA3' in g2:\n",
    "    #     continue\n",
    "    # print(g1, g2)    \n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i, g1, g2)\n",
    "    g1_mask = ((means.obs['a'] == g1) & means.obs['b'].str.contains('ctrl')) | ((means.obs['b'] == g1) & means.obs['a'].str.contains('ctrl'))\n",
    "    g2_mask = ((means.obs['a'] == g2) & means.obs['b'].str.contains('ctrl')) | ((means.obs['b'] == g2) & means.obs['a'].str.contains('ctrl'))\n",
    "    g12_mask = ((means.obs['a'] == g1) & (means.obs['b'] == g2)) | ((means.obs['a'] == g2) & (means.obs['b'] == g1))\n",
    "    g0_mask = (means.obs.index == 'ctrl')\n",
    "\n",
    "    ab = means[g12_mask.values,:] \n",
    "    a = means[g1_mask.values,:]\n",
    "    b = means[g2_mask.values,:]\n",
    "    ctrl = means[g0_mask,:]\n",
    "\n",
    "    outpath = '../../data/rf_genes/%s_%s.tsv.gz' % (g1, g2)\n",
    "    if os.path.exists(outpath):\n",
    "        continue\n",
    "    # outpath2 = '../../data/rf_genes/%s_%s.pkl' % g2, g1\n",
    "    \n",
    "    # print(ab.shape, a.shape, b.shape, ctrl.shape)\n",
    "    # b = means[means.obs['a'].str.contains(g2) | means.obs['b'].str.contains('ctrl'),:]\n",
    "\n",
    "    pred = pd.concat([ab.to_df(), a.to_df(), b.to_df(), ctrl.to_df()])\n",
    "    top_100 = pred.var(axis=0).sort_values()[::-1][:100].index\n",
    "    for c in pred:\n",
    "        pred[c] = (pred[c] - np.mean(pred[c])) / np.std(pred[c])\n",
    "    pred = pred.T.reindex(top_100).T\n",
    "    pred = pred[pred.index != 'ctrl']\n",
    "    pred = pred.T\n",
    "\n",
    "    pred_cols = []\n",
    "    for c in pred:\n",
    "        # print(c)\n",
    "        a, b = c.split('+')\n",
    "        c = (a + '+' + b) if (a > b or a == 'ctrl') else (b + '+' + a)\n",
    "        pred_cols.append(c)\n",
    "    pred.columns = pred_cols\n",
    "    pred = pred.T\n",
    "    pred = pred.groupby(pred.index).mean()\n",
    "    \n",
    "    # print(pred.shape)\n",
    "    pd.Series(pred.T.index).to_csv(outpath)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.shape\n",
    "# len(queries)\n",
    "# # queries = [[a, b] for a, b in queries if a == 'KLF1' or b == 'KLF1']\n",
    "# len(queries)\n",
    "# from ThreadingUtils import ThreadingUtils\n",
    "# ThreadingUtils.run(calculate_rf_multithread, queries, n_cores=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mypython3] *",
   "language": "python",
   "name": "conda-env-mypython3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
